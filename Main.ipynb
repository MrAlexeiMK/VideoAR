{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Userful links:\n",
    "https://docs.opencv.org/3.4/d7/dff/tutorial_feature_homography.html  \n",
    "https://www.youtube.com/playlist?list=PLMoSUbG1Q_r-JNMQ0zJmv6SnXwgbA8JJp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = ResizeWithAspectRatio(cv2.imread('patterns/chessBoard_9x7.png'), width=720)\n",
    "patternGray = cv2.cvtColor(pattern, cv2.COLOR_BGR2GRAY)\n",
    "H, W, _ = pattern.shape\n",
    "\n",
    "video = cv2.VideoCapture('videos/fractals.mp4')\n",
    "_, imgVideo = video.read()\n",
    "imgVideo = cv2.resize(imgVideo, (W, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT keypoints detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sift keypoints visualize\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    frame = ResizeWithAspectRatio(frame, width=720)\n",
    "    if ret:\n",
    "        (keypoints, descriptors) = sift.detectAndCompute(frame, None)\n",
    "        for kp in keypoints:\n",
    "            x, y = kp.pt\n",
    "            x = int(round(x))\n",
    "            y = int(round(y))\n",
    "            cv2.drawMarker(frame, (x, y), (255, 255, 255), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1, line_type=cv2.LINE_8)\n",
    "        cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB keypoints descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORB algorithm\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "orb = cv2.ORB_create(nfeatures=1000, fastThreshold=0, edgeThreshold=0)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(patternGray, None)\n",
    "detect = False\n",
    "framesCount = 0\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    imgAug = frame.copy()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp2, des2 = orb.detectAndCompute(gray, None)\n",
    "        \n",
    "        if detect == False:\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "            framesCount = 0\n",
    "        else:\n",
    "            if framesCount == video.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                framesCount = 0\n",
    "            _, imgVideo = video.read()\n",
    "            imgVideo = cv2.resize(imgVideo, (W, H))\n",
    "        \n",
    "        if des1 is not None and des2 is not None:\n",
    "            matches = bf.match(des1, des2)\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "            good = []\n",
    "\n",
    "            for k in range(0, min(50, len(matches))):\n",
    "                m = matches[k]\n",
    "                if m.distance < 30:\n",
    "                    good.append(m)\n",
    "\n",
    "            if len(good) > 40:\n",
    "                detect = True\n",
    "                srcPts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                dstPts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "                matrix, _ = cv2.findHomography(srcPts, dstPts, cv2.RANSAC, 5.0)\n",
    "                \n",
    "                if matrix is None:\n",
    "                    framesCount +=1\n",
    "                    continue\n",
    "                pts = np.float32([[0, 0], [0, H-1], [W-1, H-1], [W-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "                dst = cv2.perspectiveTransform(pts, matrix)\n",
    "                imgPol = cv2.polylines(frame, [np.int32(dstPts)], True, (255, 0, 255), 3)\n",
    "\n",
    "                imgWarp = cv2.warpPerspective(imgVideo, matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                maskNew = np.zeros((frame.shape[0], frame.shape[1]), np.uint8)\n",
    "                \n",
    "                cv2.fillPoly(maskNew, [np.int32(dst)], (255, 255, 255))\n",
    "                maskInv = cv2.bitwise_not(maskNew)\n",
    "                imgAug = cv2.bitwise_and(imgAug, imgAug, mask = maskInv)\n",
    "                imgAug = cv2.bitwise_or(imgWarp, imgAug)\n",
    "\n",
    "                match = cv2.drawMatches(pattern, kp1, frame, kp2, good, None, flags=0)\n",
    "                #cv2.imshow('frame', frame)\n",
    "                cv2.imshow('match', match)\n",
    "                #cv2.imshow('imgPol', imgPol)\n",
    "                #cv2.imshow('aug', imgAug)\n",
    "                cv2.imshow('warp', imgWarp)\n",
    "                #cv2.imshow('imgVideo', imgVideo)\n",
    "            else:\n",
    "                cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    framesCount +=1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT keypoints descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIFT algorithm\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(patternGray, None)\n",
    "\n",
    "\n",
    "detect = False\n",
    "framesCount = 0\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    imgAug = frame.copy()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp2, des2 = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        if detect == False:\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "            framesCount = 0\n",
    "        else:\n",
    "            if framesCount == video.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                framesCount = 0\n",
    "            _, imgVideo = video.read()\n",
    "            imgVideo = cv2.resize(imgVideo, (W, H))\n",
    "        \n",
    "        if des1 is not None and des2 is not None:\n",
    "            matches = flann.knnMatch(des1, des2, k=2)\n",
    "            \n",
    "            good = []\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.8*n.distance:\n",
    "                    good.append(m)\n",
    "            \n",
    "            if len(good) > 20:\n",
    "                detect = True\n",
    "                srcPts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                dstPts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "                matrix, mask = cv2.findHomography(srcPts, dstPts, cv2.RANSAC, 5.0)\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "                \n",
    "                if matrix is None:\n",
    "                    framesCount +=1\n",
    "                    continue\n",
    "                pts = np.float32([[0, 0], [0, H-1], [W-1, H-1], [W-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "                dst = cv2.perspectiveTransform(pts, matrix)\n",
    "                imgPol = cv2.polylines(frame, [np.int32(dstPts)], True, (255, 0, 255), 3)\n",
    "\n",
    "                imgWarp = cv2.warpPerspective(imgVideo, matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                maskNew = np.zeros((frame.shape[0], frame.shape[1]), np.uint8)\n",
    "                \n",
    "                cv2.fillPoly(maskNew, [np.int32(dst)], (255, 255, 255))\n",
    "                maskInv = cv2.bitwise_not(maskNew)\n",
    "                imgAug = cv2.bitwise_and(imgAug, imgAug, mask = maskInv)\n",
    "                imgAug = cv2.bitwise_or(imgWarp, imgAug)\n",
    "                \n",
    "                draw_params = dict(matchColor = (255, 0, 0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "                match = cv2.drawMatches(pattern, kp1, frame, kp2, good, None, **draw_params)\n",
    "                #cv2.imshow('frame', frame)\n",
    "                cv2.imshow('match', match)\n",
    "                #cv2.imshow('imgPol', imgPol)\n",
    "                #cv2.imshow('aug', imgAug)\n",
    "                #cv2.imshow('warp', imgWarp)\n",
    "                #cv2.imshow('imgVideo', imgVideo)\n",
    "            else:\n",
    "                cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    framesCount +=1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess board pattern recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chess board pattern algorithm\n",
    "\n",
    "nX = 10\n",
    "nY = 7\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "ret1, kp1 = cv2.findChessboardCorners(patternGray, (nX-1, nY-1), None)\n",
    "if ret1:\n",
    "    detect = False\n",
    "    framesCount = 0\n",
    "\n",
    "    while(cam.isOpened()):\n",
    "        ret, frame = cam.read()\n",
    "        imgAug = frame.copy()\n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            ret2, kp2 = cv2.findChessboardCorners(gray, (nX-1, nY-1), None,\n",
    "                            cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK)\n",
    "\n",
    "            if detect == False:\n",
    "                video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                framesCount = 0\n",
    "            else:\n",
    "                if framesCount == video.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                    video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    framesCount = 0\n",
    "                _, imgVideo = video.read()\n",
    "                imgVideo = cv2.resize(imgVideo, (W, H))\n",
    "            \n",
    "            if ret2:\n",
    "                detect = True\n",
    "                \n",
    "                matrix, _ = cv2.findHomography(kp1, kp2, cv2.RANSAC, 5.0)\n",
    "                \n",
    "                if matrix is None:\n",
    "                    framesCount += 1\n",
    "                    continue\n",
    "                pts = np.float32([[0, 0], [0, H-1], [W-1, H-1], [W-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "                dst = cv2.perspectiveTransform(pts, matrix)\n",
    "\n",
    "                imgWarp = cv2.warpPerspective(imgVideo, matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                maskNew = np.zeros((frame.shape[0], frame.shape[1]), np.uint8)\n",
    "                \n",
    "                cv2.fillPoly(maskNew, [np.int32(dst)], (255, 255, 255))\n",
    "                maskInv = cv2.bitwise_not(maskNew)\n",
    "                imgAug = cv2.bitwise_and(imgAug, imgAug, mask = maskInv)\n",
    "                imgAug = cv2.bitwise_or(imgWarp, imgAug)\n",
    "                \n",
    "                cv2.imshow('frame', imgAug)\n",
    "            else:\n",
    "                cv2.imshow('frame', frame)\n",
    "            \n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        framesCount +=1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "else:\n",
    "    print(\"Chess board pattern not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
